{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsiecker/Deep-Learning/blob/Task-1/assignment_2/Assignment_2_2AMM10_22_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Details\n",
        "\n",
        "## Group Name: group21\n",
        "\n",
        "### Student 1: N.P.G.T. van Beuningen\t1353624\n",
        "\n",
        "### Student 2: D.P.M. van der Hoorn\t1873334\n",
        "\n",
        "### Student 3: L.R. Siecker\t1344838"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Loading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://github.com/lsiecker/Deep-Learning/raw/main/assignment_2/data/\""
      ],
      "metadata": {
        "id": "-QWOrWC_Nktn"
      },
      "id": "-QWOrWC_Nktn",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(url, task):\n",
        "    \"\"\"\n",
        "    Loads a numpy array from surfdrive. \n",
        "    \n",
        "    Input:\n",
        "    url: Download link of dataset \n",
        "    \n",
        "    Outputs:\n",
        "    dataset: numpy array with input features or labels\n",
        "    \"\"\"\n",
        "    \n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    array = load_array(io.BytesIO(response.content), task)\n",
        "\n",
        "    return array"
      ],
      "metadata": {
        "id": "PhNbEmijMe1p"
      },
      "id": "PhNbEmijMe1p",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pLOkTq4li8ip"
      },
      "id": "pLOkTq4li8ip"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_array(filename, task):\n",
        "    datapoint = np.load(filename)\n",
        "    if task == 'task 1':\n",
        "        initial_state = datapoint['initial_state']\n",
        "        terminal_state = datapoint['terminal_state']\n",
        "        return initial_state, terminal_state\n",
        "    elif task == 'task 2' or task == 'task 3':\n",
        "        whole_trajectory = datapoint['trajectory']\n",
        "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
        "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
        "        initial_state = whole_trajectory[:, 0]\n",
        "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
        "        return initial_state, target\n",
        "    else:\n",
        "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be",
        "outputId": "a37afae6-3e13-4b11-d8d1-bbfc333446b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 2)\n",
            "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 1.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "terminal_state: shape (n_bodies, [x, y])\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "example = load_data(f\"{base_url}task%201/train/trajectory_0.npz?raw=true\", task='task 1')\n",
        "\n",
        "initial_state, terminal_state = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1c3ea4cb",
      "metadata": {
        "id": "1c3ea4cb",
        "outputId": "01deff3d-8599-4fdf-fa33-ca2964d51bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
            "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
            "the shape of the input of a test data example is (8, 5)\n",
            "the shape of the target of a test data example is (8, 49, 4)\n",
            "values of the test data example at time 30:\n",
            " [[-1.11611543  3.21149953         nan         nan]\n",
            " [-0.2865083   4.30801877         nan         nan]\n",
            " [ 1.07701594 -8.12529269         nan         nan]\n",
            " [-0.92053478  3.13709551         nan         nan]\n",
            " [-3.96308297 -4.27733589         nan         nan]\n",
            " [ 2.33945401 -8.67733599         nan         nan]\n",
            " [-4.83949085  3.67854952         nan         nan]\n",
            " [ 0.31080159 -9.74720071         nan         nan]]\n",
            "note: velocity values are unobserved (NaNs) in the test data!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
        "\n",
        "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
        "If you use the velocity of the remaining trajectory for training,\n",
        "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
        "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "example = load_data(f'{base_url}task%202_3/train/trajectory_0.npz', task='task 2')\n",
        "\n",
        "initial_state, remaining_trajectory = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "time_idx = 30\n",
        "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
        "\n",
        "test_example = load_data(f'{base_url}task 2_3/test/trajectory_900.npz', task='task 3')\n",
        "test_initial_state, test_remaining_trajectory = test_example\n",
        "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
        "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
        "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
        "print('note: velocity values are unobserved (NaNs) in the test data!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "10a3438a",
      "metadata": {
        "id": "10a3438a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d28681a6",
      "metadata": {
        "id": "d28681a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task **1**"
      ],
      "metadata": {
        "id": "XTN_Ug4wNBoG"
      },
      "id": "XTN_Ug4wNBoG"
    },
    {
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Get all training data \"\"\"\n",
        "train_data = []\n",
        "for i in range(0,900):\n",
        "  train_data.append(load_data(f\"{base_url}task%201/train/trajectory_{i}.npz?raw=true\", task='task 1'))\n"
      ],
      "metadata": {
        "id": "56ebOaDPlIrR"
      },
      "id": "56ebOaDPlIrR",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Get all test data \"\"\"\n",
        "test_data = []\n",
        "for i in range(900, 1000):\n",
        "  test_data.append(load_data(f\"{base_url}task%201/test/trajectory_{i}.npz?raw=true\", task='task 1'))"
      ],
      "metadata": {
        "id": "u6POghJBqf1n"
      },
      "id": "u6POghJBqf1n",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Create training, validation and test sets \"\"\"\n",
        "train_x = [torch.tensor(array[0]) for array in train_data[:800]]\n",
        "train_y = [torch.tensor(array[1]) for array in train_data[:800]]\n",
        "val_x = [torch.tensor(array[0]) for array in train_data[800:]]\n",
        "val_y = [torch.tensor(array[1]) for array in train_data[800:]]\n",
        "test_x = [torch.tensor(array[0]) for array in test_data]\n",
        "test_y = [torch.tensor(array[1]) for array in test_data]\n"
      ],
      "metadata": {
        "id": "MODD-LJEliIN"
      },
      "id": "MODD-LJEliIN",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "train_x_pad = pad_sequence(train_x, batch_first=True, padding_value=0) #add padding since some some observations have more objects than others\n",
        "train_y_pad = pad_sequence(train_y, batch_first=True, padding_value=0)\n",
        "val_x_pad = pad_sequence(val_x, batch_first=True, padding_value=0)\n",
        "val_y_pad = pad_sequence(val_y, batch_first=True, padding_value=0)\n",
        "test_x_pad = pad_sequence(test_x, batch_first=True, padding_value=0)\n",
        "test_y_pad = pad_sequence(test_y, batch_first=True, padding_value=0)\n",
        "\n",
        "train_dataset = TensorDataset(train_x_pad, train_y_pad)\n",
        "val_dataset = TensorDataset(val_x_pad, val_y_pad)\n",
        "test_dataset = TensorDataset(test_x_pad, test_y_pad)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=100, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)"
      ],
      "metadata": {
        "id": "M9UWHZergZE7"
      },
      "id": "M9UWHZergZE7",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "66774050",
      "metadata": {
        "id": "66774050"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "ba598378",
      "metadata": {
        "id": "ba598378"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TrainPointPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward(self, points, padded_points):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "95154df7",
      "metadata": {
        "id": "95154df7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_correct, total_count = 0,0\n",
        "  log_interval = 500\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (trajectory_points, padded_points) in enumerate(dataloader):\n",
        "    trajectory_points = trajectory_points.to(device)\n",
        "    padded_points = padded_points.to(device)\n",
        "\n",
        "    model.optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(trajectory_points, padded_points)\n",
        "\n",
        "    # TODO classes are kind of continuous in this task\n",
        "    loss = model.criterion(y_pred.permute((0,2,1)), padded_points)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        \n",
        "    model.optimizer.step()\n",
        "    \n",
        "    total_correct += (y_pred.argmax(2) == padded_points).sum().item()\n",
        "    total_count += padded_points.size(0) * 35\n",
        "    \n",
        "    \n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "              '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                          total_correct/total_count))\n",
        "        total_correct, total_count = 0, 0\n",
        "        start_time = time.time()\n",
        "            \n",
        "    return total_correct/total_count\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_correct, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (trajectory_points, padded_points) in enumerate(dataloader):\n",
        "            \n",
        "            trajectory_points = trajectory_points.to(device)\n",
        "            padded_points = padded_points.to(device)\n",
        "            \n",
        "            y_pred = requests.models(trajectory_points, padded_points)\n",
        "            \n",
        "            # TODO: classes are kind of continuous in this case\n",
        "            loss = model.criterion(..., padded_points)\n",
        "            \n",
        "            total_correct += (y_pred.argmax(2) == padded_points).sum().item()\n",
        "            total_count += padded_points.size(0) * 35\n",
        "\n",
        "    return total_correct/total_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMETERS\n",
        "EPOCHS = 10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = TrainPointPredictor().to(device)\n",
        "\n",
        "train_acc, val_acc = [], []\n",
        "# training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    train_acc.append(train(train_dataloader))\n",
        "    val_acc.append(evaluate(val_dataloader))\n",
        "    \n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'train accuracy {:8.3f} '\n",
        "          'validation accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time, \n",
        "                                           train_acc[-1],\n",
        "                                           val_acc[-1]))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "id": "KCukvrhsLWt_",
        "outputId": "ccec3e41-998e-4646-a163-a10bb9445585",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "id": "KCukvrhsLWt_",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-648087cb6419>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainPointPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mchildren\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2171\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mchild\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m         \"\"\"\n\u001b[0;32m-> 2173\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2174\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mnamed_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2190\u001b[0m         \"\"\"\n\u001b[1;32m   2191\u001b[0m         \u001b[0mmemo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2192\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2194\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TrainPointPredictor' object has no attribute '_modules'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3af520ae",
      "metadata": {
        "id": "3af520ae"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e95af5f9",
      "metadata": {
        "id": "e95af5f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "07e03ddf",
      "metadata": {
        "id": "07e03ddf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d5fb3b29",
      "metadata": {
        "id": "d5fb3b29"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bf5fa1b4",
      "metadata": {
        "id": "bf5fa1b4"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2280031f",
      "metadata": {
        "id": "2280031f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3a8240f1",
      "metadata": {
        "id": "3a8240f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task **2**"
      ],
      "metadata": {
        "id": "zscir61wNPq-"
      },
      "id": "zscir61wNPq-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5o3OwsNPq-"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ],
      "id": "GA5o3OwsNPq-"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "wN0DiVWRNPq-"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "wN0DiVWRNPq-"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1oFwPOUeNPq-"
      },
      "outputs": [],
      "source": [],
      "id": "1oFwPOUeNPq-"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-1aS1_vLNPq_"
      },
      "outputs": [],
      "source": [],
      "id": "-1aS1_vLNPq_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBddgkOCNPq_"
      },
      "source": [
        "## Model Implementation"
      ],
      "id": "CBddgkOCNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nXN3oainNPq_"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "nXN3oainNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ed5riNqMNPq_"
      },
      "outputs": [],
      "source": [],
      "id": "ed5riNqMNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Yx_mTiE2NPq_"
      },
      "outputs": [],
      "source": [],
      "id": "Yx_mTiE2NPq_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk0mwW_MNPq_"
      },
      "source": [
        "## Model Training"
      ],
      "id": "Bk0mwW_MNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z80Hu0j_NPq_"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "Z80Hu0j_NPq_"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BeLdvBlzNPq_"
      },
      "outputs": [],
      "source": [],
      "id": "BeLdvBlzNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vH7NfGo_NPrA"
      },
      "outputs": [],
      "source": [],
      "id": "vH7NfGo_NPrA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXONKz3BNPrA"
      },
      "source": [
        "## Evaluation"
      ],
      "id": "SXONKz3BNPrA"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gHUaCY69NPrA"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "gHUaCY69NPrA"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u-Zuv88WNPrA"
      },
      "outputs": [],
      "source": [],
      "id": "u-Zuv88WNPrA"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g9R4m3FfNPrA"
      },
      "outputs": [],
      "source": [],
      "id": "g9R4m3FfNPrA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task **3**"
      ],
      "metadata": {
        "id": "3BBkYM98NQ2n"
      },
      "id": "3BBkYM98NQ2n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R74UD15nNQ2u"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ],
      "id": "R74UD15nNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UtTgTtATNQ2u"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "UtTgTtATNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SIiFNKSdNQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "SIiFNKSdNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "t-dHrZe1NQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "t-dHrZe1NQ2u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux93FaRNNQ2u"
      },
      "source": [
        "## Model Implementation"
      ],
      "id": "Ux93FaRNNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OKmPXlKVNQ2u"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "OKmPXlKVNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "odGl5mAJNQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "odGl5mAJNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ttow-qaZNQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "ttow-qaZNQ2u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5inw0JHbNQ2v"
      },
      "source": [
        "## Model Training"
      ],
      "id": "5inw0JHbNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VK3Fy9oyNQ2v"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "VK3Fy9oyNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "AXW-7sOhNQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "AXW-7sOhNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "APgtOl2vNQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "APgtOl2vNQ2v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ75b5zENQ2v"
      },
      "source": [
        "## Evaluation"
      ],
      "id": "kQ75b5zENQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RRvbQKryNQ2v"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "RRvbQKryNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FhT9U3qoNQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "FhT9U3qoNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FmKWcGcENQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "FmKWcGcENQ2v"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zscir61wNPq-",
        "3BBkYM98NQ2n"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}