{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsiecker/Deep-Learning/blob/main/assignment_2/Assignment_2_2AMM10_22_23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d32f8d18",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Details\n",
        "\n",
        "## Group Name: group21\n",
        "\n",
        "### Student 1: N.P.G.T. van Beuningen\t1353624\n",
        "\n",
        "### Student 2: D.P.M. van der Hoorn\t1873334\n",
        "\n",
        "### Student 3: L.R. Siecker\t1344838"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faec2056",
      "metadata": {
        "id": "faec2056"
      },
      "source": [
        "# Loading Data and Preliminaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7d0580a5",
      "metadata": {
        "id": "7d0580a5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import io\n",
        "import requests\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://github.com/lsiecker/Deep-Learning/raw/main/assignment_2/data/\""
      ],
      "metadata": {
        "id": "-QWOrWC_Nktn"
      },
      "id": "-QWOrWC_Nktn",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(url, task):\n",
        "    \"\"\"\n",
        "    Loads a numpy array from surfdrive. \n",
        "    \n",
        "    Input:\n",
        "    url: Download link of dataset \n",
        "    \n",
        "    Outputs:\n",
        "    dataset: numpy array with input features or labels\n",
        "    \"\"\"\n",
        "    \n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    array = load_array(io.BytesIO(response.content), task)\n",
        "\n",
        "    return array"
      ],
      "metadata": {
        "id": "PhNbEmijMe1p"
      },
      "id": "PhNbEmijMe1p",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pLOkTq4li8ip"
      },
      "id": "pLOkTq4li8ip"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b0756591",
      "metadata": {
        "id": "b0756591"
      },
      "outputs": [],
      "source": [
        "def load_array(filename, task):\n",
        "    datapoint = np.load(filename)\n",
        "    if task == 'task 1':\n",
        "        initial_state = datapoint['initial_state']\n",
        "        terminal_state = datapoint['terminal_state']\n",
        "        return initial_state, terminal_state\n",
        "    elif task == 'task 2' or task == 'task 3':\n",
        "        whole_trajectory = datapoint['trajectory']\n",
        "        # change shape: (num_bodies, attributes, time) ->  num_bodies, time, attributes\n",
        "        whole_trajectory = np.swapaxes(whole_trajectory, 1, 2)\n",
        "        initial_state = whole_trajectory[:, 0]\n",
        "        target = whole_trajectory[:, 1:, 1:]  # drop the first timepoint (second dim) and mass (last dim) for the prediction task\n",
        "        return initial_state, target\n",
        "    else:\n",
        "        raise NotImplementedError(\"'task' argument should be 'task 1', 'task 2' or 'task 3'!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bb77a4be",
      "metadata": {
        "id": "bb77a4be",
        "outputId": "79116ff8-d62a-4351-8096-cb3f47bd7a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 2)\n",
            "The initial x-coordinate of the body with index 2 in this trajectory was -5.159721083543527\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 1.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "terminal_state: shape (n_bodies, [x, y])\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "example = load_data(f\"{base_url}task%201/train/trajectory_0.npz?raw=true\", task='task 1')\n",
        "\n",
        "initial_state, terminal_state = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {terminal_state.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "print(f'The initial x-coordinate of the body with index {body_idx} in this trajectory was {initial_state[body_idx, 1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1c3ea4cb",
      "metadata": {
        "id": "1c3ea4cb",
        "outputId": "ea0485f7-f75a-4d68-ba0c-65552010677d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of initial state (model input): (8, 5)\n",
            "shape of terminal state (to be predicted by model): (8, 49, 4)\n",
            "The y-coordinate of the body with index 2 at time with index 30 in remaining_trajectory was -0.3861544940435097\n",
            "the shape of the input of a test data example is (8, 5)\n",
            "the shape of the target of a test data example is (8, 49, 4)\n",
            "values of the test data example at time 30:\n",
            " [[-1.11611543  3.21149953         nan         nan]\n",
            " [-0.2865083   4.30801877         nan         nan]\n",
            " [ 1.07701594 -8.12529269         nan         nan]\n",
            " [-0.92053478  3.13709551         nan         nan]\n",
            " [-3.96308297 -4.27733589         nan         nan]\n",
            " [ 2.33945401 -8.67733599         nan         nan]\n",
            " [-4.83949085  3.67854952         nan         nan]\n",
            " [ 0.31080159 -9.74720071         nan         nan]]\n",
            "note: velocity values are unobserved (NaNs) in the test data!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This cell gives an example of loading a datapoint with numpy for task 2 / 3.\n",
        "\n",
        "The arrays returned by the function are structures as follows:\n",
        "initial_state: shape (n_bodies, [mass, x, y, v_x, v_y])\n",
        "remaining_trajectory: shape (n_bodies, time, [x, y, v_x, v_y])\n",
        "\n",
        "Note that for this task, you are asked to evaluate performance only with regard to the predictions of the positions (x and y).\n",
        "If you use the velocity of the remaining trajectory for training,\n",
        "this use should be purely auxiliary for the goal of predicting the positions [x,y] over time. \n",
        "While testing performance of your model on the test set, you do not have access to v_x and v_y of the remaining trajectory.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "example = load_data(f'{base_url}task%202_3/train/trajectory_0.npz', task='task 2')\n",
        "\n",
        "initial_state, remaining_trajectory = example\n",
        "print(f'shape of initial state (model input): {initial_state.shape}')\n",
        "print(f'shape of terminal state (to be predicted by model): {remaining_trajectory.shape}')\n",
        "\n",
        "body_idx = 2\n",
        "time_idx = 30\n",
        "print(f'The y-coordinate of the body with index {body_idx} at time with index {time_idx} in remaining_trajectory was {remaining_trajectory[body_idx, time_idx, 1]}')\n",
        "\n",
        "test_example = load_data(f'{base_url}task 2_3/test/trajectory_900.npz', task='task 3')\n",
        "test_initial_state, test_remaining_trajectory = test_example\n",
        "print(f'the shape of the input of a test data example is {test_initial_state.shape}')\n",
        "print(f'the shape of the target of a test data example is {test_remaining_trajectory.shape}')\n",
        "print(f'values of the test data example at time {time_idx}:\\n {test_remaining_trajectory[:, time_idx]}')\n",
        "print('note: velocity values are unobserved (NaNs) in the test data!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "10a3438a",
      "metadata": {
        "id": "10a3438a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f9106543",
      "metadata": {
        "id": "f9106543"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d28681a6",
      "metadata": {
        "id": "d28681a6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task **1**"
      ],
      "metadata": {
        "id": "XTN_Ug4wNBoG"
      },
      "id": "XTN_Ug4wNBoG"
    },
    {
      "cell_type": "markdown",
      "id": "059b633c",
      "metadata": {
        "id": "059b633c"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Get all training data \"\"\"\n",
        "train_data = []\n",
        "for i in range(0,900):\n",
        "  train_data.append(load_data(f\"{base_url}task%201/train/trajectory_{i}.npz?raw=true\", task='task 1'))\n"
      ],
      "metadata": {
        "id": "56ebOaDPlIrR"
      },
      "id": "56ebOaDPlIrR",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Get all test data \"\"\"\n",
        "test_data = []\n",
        "for i in range(900, 1000):\n",
        "  test_data.append(load_data(f\"{base_url}task%201/test/trajectory_{i}.npz?raw=true\", task='task 1'))"
      ],
      "metadata": {
        "id": "u6POghJBqf1n"
      },
      "id": "u6POghJBqf1n",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Create training, validation and test sets \"\"\"\n",
        "train_x = [torch.tensor(array[0]) for array in train_data[:800]]\n",
        "train_y = [torch.tensor(array[1]) for array in train_data[:800]]\n",
        "val_x = [torch.tensor(array[0]) for array in train_data[800:]]\n",
        "val_y = [torch.tensor(array[1]) for array in train_data[800:]]\n",
        "test_x = [torch.tensor(array[0]) for array in test_data]\n",
        "test_y = [torch.tensor(array[1]) for array in test_data]\n"
      ],
      "metadata": {
        "id": "MODD-LJEliIN"
      },
      "id": "MODD-LJEliIN",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import numpy as np\n",
        "\n",
        "def collate_batch(batch):\n",
        "    \"\"\"\n",
        "    Concatenate multiple datapoints to obtain a single batch of data\n",
        "    \"\"\"\n",
        "    # sentences are stored as tuples; get respective lists\n",
        "    source_points = [x[0] for x in batch]\n",
        "    target_points = [x[1] for x in batch]\n",
        "\n",
        "    # pad sequences in batch\n",
        "    source_padded = pad_sequence(sequences = source_points, \n",
        "                             batch_first = True)\n",
        "    target_padded = pad_sequence(sequences = target_points, \n",
        "                             batch_first = True)\n",
        "\n",
        "    # return source (DE) and target sequences (EN) after transferring them to GPU (if available)\n",
        "    return source_padded.to(device).T, target_padded.to(device).T\n",
        "\n",
        "\n",
        "train_x_pad = pad_sequence(train_x, batch_first=True) #add padding since some some observations have more objects than others\n",
        "train_y_pad = pad_sequence(train_y, batch_first=True)\n",
        "val_x_pad = pad_sequence(val_x, batch_first=True)\n",
        "val_y_pad = pad_sequence(val_y, batch_first=True)\n",
        "test_x_pad = pad_sequence(test_x, batch_first=True)\n",
        "test_y_pad = pad_sequence(test_y, batch_first=True)\n",
        "\n",
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "val_dataset = TensorDataset(val_x, val_y)\n",
        "test_dataset = TensorDataset(test_x, test_y)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=100, collate_fn=collate_batch)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=100, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=100, collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "M9UWHZergZE7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "b9dc43b5-42a3-4afd-e989-f94b8e2d060f"
      },
      "id": "M9UWHZergZE7",
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-ff88dbbfa402>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtest_y_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0OPHpH69XdQl"
      },
      "id": "0OPHpH69XdQl"
    },
    {
      "cell_type": "markdown",
      "id": "18b2874d",
      "metadata": {
        "id": "18b2874d"
      },
      "source": [
        "## Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "66774050",
      "metadata": {
        "id": "66774050"
      },
      "outputs": [],
      "source": [
        "#todo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        ### Your code here ###\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        \n",
        "    def forward(self, src):\n",
        "        \"\"\"\n",
        "        Forward pass of encoder model. It aims at\n",
        "        transforming the input sentence to a dense vector \n",
        "        \n",
        "        Input:\n",
        "        src shape:  [max_seq_len_in_batch, batch_size]\n",
        "\n",
        "        Output:\n",
        "        hidden and cell dense vectors (hidden and cell)\n",
        "        which contains all sentence information, shape [n layers, batch size, hid dim]\n",
        "        \"\"\"\n",
        "        \n",
        "        ### Your code here ###\n",
        "        #src = [src len, batch size]\n",
        "        src = src.to(torch.float32)\n",
        "        _, (hidden, cell) = self.rnn(src)\n",
        "        \n",
        "        return hidden, cell"
      ],
      "metadata": {
        "id": "UbfrfWZgAw7f"
      },
      "id": "UbfrfWZgAw7f",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        ### Your code here ###\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "        \n",
        "    def forward(self, input, hidden, cell):\n",
        "        \"\"\"\n",
        "        Forward pass of the decoder model. It aims at transforming\n",
        "        the dense representation of the encoder into a sentence in\n",
        "        the target language\n",
        "        \n",
        "        Input:\n",
        "        hidden shape: [n layers, batch size, hid dim]\n",
        "        cell shape: [n layers, batch size, hid dim]\n",
        "        input shape: [batch size]  # 1 token for each sentence in the batch\n",
        "        \n",
        "        Output:\n",
        "        prediction shape: [batch size, num_words_target_vocabulary]\n",
        "        hidden shape: [n layers, batch size, hid dim]\n",
        "        cell shape: [n layers, batch size, hid dim]\n",
        "        \"\"\"\n",
        "        \n",
        "        ### Your code here ###\n",
        "        # pytorch expects a sequence, but we use batches with 1 element, i.e., sequence length 1\n",
        "        input = input.unsqueeze(0).to(torch.float32)\n",
        "        #input = [1, batch size]\n",
        "        \n",
        "        #embedded = [1, batch size, emb dim]         \n",
        "        output, (hidden, cell) = self.rnn(input, (hidden, cell))\n",
        "        #output = [1, batch size, hid dim]\n",
        "        \n",
        "        prediction = self.fc_out(output.squeeze(0))  # squeeze our 'sequence length 1' away\n",
        "        #prediction = [batch size, output dim]\n",
        "        \n",
        "        return prediction, hidden, cell"
      ],
      "metadata": {
        "id": "vNXVspTGAw-H"
      },
      "id": "vNXVspTGAw-H",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "ba598378",
      "metadata": {
        "id": "ba598378"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim\n",
        "import random\n",
        "\n",
        "class TrainPointPredictor(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "        \n",
        "        ### Your code here ###\n",
        "        self.optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        \n",
        "        self.criterion = nn.MSELoss()\n",
        "        \n",
        "\n",
        "    def forward(self, source_points, target_points, teacher_forcing_ratio = 0.5):\n",
        "        \"\"\"\n",
        "        Forward pass of the seq2seq model. It encodes the source sentence into\n",
        "        a dense representation and thereafter transduces into the target\n",
        "        sentence.\n",
        "        \n",
        "        Inputs:\n",
        "        src: padded index representation of source sentences with shape [src len, batch size]\n",
        "        trg:  padded index representation of target sentences with shape [trg len, batch size]\n",
        "        teacher_forcing_ratio: probability to use teacher forcing, e.g. 0.5 we use ground-truth target sentence 50% of the time\n",
        "        \n",
        "        Outputs:\n",
        "        outputs: padded index representation of the predicted sentences with shape [trg_len, batch_size, trg_vocab_size]\n",
        "        \"\"\"\n",
        "        \n",
        "        #src = [src len, batch size]\n",
        "        #trg = [trg len, batch size]\n",
        "        #teacher_forcing_ratio is probability to use teacher forcing\n",
        "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
        "        \n",
        "        batch_size = target_points.shape[1]\n",
        "        trg_len = target_points.shape[0]\n",
        "        \n",
        "        ### Your code here ###\n",
        "        #tensor to store decoder outputs\n",
        "        outputs = torch.zeros(trg_len, batch_size, 2).to(self.device)\n",
        "        print(f\"Source shape: {source_points.shape}\")\n",
        "        print(f\"Target shape: {target_points.shape}\")\n",
        "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
        "        hidden, cell = self.encoder(source_points)\n",
        "        \n",
        "        #first input to the decoder is the <sos> tokens\n",
        "        input = target_points[0]\n",
        "        for t in range(1, trg_len):\n",
        "            #insert input token embedding, previous hidden and previous cell states\n",
        "            #receive output tensor (predictions) and new hidden and cell states\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            \n",
        "            #place predictions in a tensor holding predictions for each token\n",
        "            outputs[t] = output\n",
        "            \n",
        "            #decide if we are going to use teacher forcing or not\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            \n",
        "            #get the highest predicted token from our predictions\n",
        "            top1 = output.argmax(1) \n",
        "            \n",
        "            #if teacher forcing, use actual next token as next input\n",
        "            #if not, use predicted token\n",
        "            input = target_points[t] if teacher_force else top1\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "95154df7",
      "metadata": {
        "id": "95154df7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  total_correct, total_count = 0,0\n",
        "  log_interval = 500\n",
        "  start_time = time.time()\n",
        "  print(\"Start training!\")\n",
        "  for idx, (trajectory_points, target_points) in enumerate(dataloader):\n",
        "    trajectory_points = trajectory_points.to(device)\n",
        "    target_points = target_points.to(device)\n",
        "\n",
        "    model.optimizer.zero_grad()\n",
        "    print(f\"Training for points with idx: {idx}\")\n",
        "    y_pred = model(trajectory_points, target_points)\n",
        "    print(\"Done training\")\n",
        "    # TODO classes are kind of continuous in this task\n",
        "    loss = model.criterion(y_pred.permute((0,2,1)), target_points)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "        \n",
        "    model.optimizer.step()\n",
        "    print(\"Calculating performance\")\n",
        "    total_correct += (y_pred.argmax(2) == target_points).sum().item()\n",
        "    total_count += target_points.size(0) * 35\n",
        "    \n",
        "    \n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "              '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                          total_correct/total_count))\n",
        "        total_correct, total_count = 0, 0\n",
        "        start_time = time.time()\n",
        "            \n",
        "    return total_correct/total_count\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_correct, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (trajectory_points, target_points) in enumerate(dataloader):\n",
        "            \n",
        "            trajectory_points = trajectory_points.to(device)\n",
        "            target_points = target_points.to(device)\n",
        "            \n",
        "            y_pred = requests.models(trajectory_points, target_points)\n",
        "            \n",
        "            # TODO: classes are kind of continuous in this case\n",
        "            loss = model.criterion(..., target_points)\n",
        "            \n",
        "            total_correct += (y_pred.argmax(2) == target_points).sum().item()\n",
        "            total_count += target_points.size(0) * 35\n",
        "\n",
        "    return total_correct/total_count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HYPERPARAMETERS\n",
        "EPOCHS = 10\n",
        "DROPOUT = 0.5\n",
        "N_LAYERS = 2\n",
        "INPUT_SIZE = 9 \n",
        "OUTPUT_SIZE = 5\n",
        "EMB_DIM = 5\n",
        "HIDDEN_DIM = 512 #dimension of the lstm's hidden state\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# initiate seq2seq translation model\n",
        "enc = Encoder(input_size=9, emb_dim=5, hid_dim=512, n_layers=2, dropout=0.5)\n",
        "dec = Decoder(output_size=2, emb_dim=2, hid_dim=512, n_layers=2, dropout=0.5)\n",
        "\n",
        "model = TrainPointPredictor(enc, dec, device).to(device)\n",
        "\n",
        "train_acc, val_acc = [], []\n",
        "# training loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "\n",
        "    train_acc.append(train(train_dataloader))\n",
        "    val_acc.append(evaluate(val_dataloader))\n",
        "    \n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'train accuracy {:8.3f} '\n",
        "          'validation accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time, \n",
        "                                           train_acc[-1],\n",
        "                                           val_acc[-1]))\n",
        "    print('-' * 59)"
      ],
      "metadata": {
        "id": "KCukvrhsLWt_",
        "outputId": "049dd71c-3389-4beb-c199-6cc7721db595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        }
      },
      "id": "KCukvrhsLWt_",
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-107-c0e3914f4c4b>:13: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  source_points = torch.from_numpy(np.array(source_points, dtype='float32'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-652d2673435a>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-f1f9d69d70bf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start training!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrajectory_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_points\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrajectory_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectory_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtarget_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_points\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-107-c0e3914f4c4b>\u001b[0m in \u001b[0;36mcollate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtarget_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msource_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mtarget_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (100,) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dea70d73",
      "metadata": {
        "id": "dea70d73"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af520ae",
      "metadata": {
        "id": "3af520ae"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e95af5f9",
      "metadata": {
        "id": "e95af5f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "07e03ddf",
      "metadata": {
        "id": "07e03ddf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d5fb3b29",
      "metadata": {
        "id": "d5fb3b29"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf5fa1b4",
      "metadata": {
        "id": "bf5fa1b4"
      },
      "outputs": [],
      "source": [
        "#todo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2280031f",
      "metadata": {
        "id": "2280031f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a8240f1",
      "metadata": {
        "id": "3a8240f1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task **2**"
      ],
      "metadata": {
        "id": "zscir61wNPq-"
      },
      "id": "zscir61wNPq-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5o3OwsNPq-"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ],
      "id": "GA5o3OwsNPq-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN0DiVWRNPq-"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "wN0DiVWRNPq-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oFwPOUeNPq-"
      },
      "outputs": [],
      "source": [],
      "id": "1oFwPOUeNPq-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1aS1_vLNPq_"
      },
      "outputs": [],
      "source": [],
      "id": "-1aS1_vLNPq_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBddgkOCNPq_"
      },
      "source": [
        "## Model Implementation"
      ],
      "id": "CBddgkOCNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXN3oainNPq_"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "nXN3oainNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed5riNqMNPq_"
      },
      "outputs": [],
      "source": [],
      "id": "ed5riNqMNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx_mTiE2NPq_"
      },
      "outputs": [],
      "source": [],
      "id": "Yx_mTiE2NPq_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk0mwW_MNPq_"
      },
      "source": [
        "## Model Training"
      ],
      "id": "Bk0mwW_MNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z80Hu0j_NPq_"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "Z80Hu0j_NPq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeLdvBlzNPq_"
      },
      "outputs": [],
      "source": [],
      "id": "BeLdvBlzNPq_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH7NfGo_NPrA"
      },
      "outputs": [],
      "source": [],
      "id": "vH7NfGo_NPrA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXONKz3BNPrA"
      },
      "source": [
        "## Evaluation"
      ],
      "id": "SXONKz3BNPrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHUaCY69NPrA"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "gHUaCY69NPrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-Zuv88WNPrA"
      },
      "outputs": [],
      "source": [],
      "id": "u-Zuv88WNPrA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9R4m3FfNPrA"
      },
      "outputs": [],
      "source": [],
      "id": "g9R4m3FfNPrA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task **3**"
      ],
      "metadata": {
        "id": "3BBkYM98NQ2n"
      },
      "id": "3BBkYM98NQ2n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R74UD15nNQ2u"
      },
      "source": [
        "## Data Handling and Preprocessing"
      ],
      "id": "R74UD15nNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtTgTtATNQ2u"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "UtTgTtATNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIiFNKSdNQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "SIiFNKSdNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-dHrZe1NQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "t-dHrZe1NQ2u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux93FaRNNQ2u"
      },
      "source": [
        "## Model Implementation"
      ],
      "id": "Ux93FaRNNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKmPXlKVNQ2u"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "OKmPXlKVNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odGl5mAJNQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "odGl5mAJNQ2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttow-qaZNQ2u"
      },
      "outputs": [],
      "source": [],
      "id": "ttow-qaZNQ2u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5inw0JHbNQ2v"
      },
      "source": [
        "## Model Training"
      ],
      "id": "5inw0JHbNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VK3Fy9oyNQ2v"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "VK3Fy9oyNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXW-7sOhNQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "AXW-7sOhNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APgtOl2vNQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "APgtOl2vNQ2v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ75b5zENQ2v"
      },
      "source": [
        "## Evaluation"
      ],
      "id": "kQ75b5zENQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRvbQKryNQ2v"
      },
      "outputs": [],
      "source": [
        "#todo"
      ],
      "id": "RRvbQKryNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhT9U3qoNQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "FhT9U3qoNQ2v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmKWcGcENQ2v"
      },
      "outputs": [],
      "source": [],
      "id": "FmKWcGcENQ2v"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zscir61wNPq-",
        "3BBkYM98NQ2n"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}